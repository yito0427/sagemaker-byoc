{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ローカルのnotebook開発から、学習ジョブ移行までを実施する"
   ]
  },
  {
   "source": [
    "# 1. ローカルノートブックで学習を行う\n",
    "・sklearnの乳がんデータを用いる（分類問題）\n",
    "・LightGBMを使う"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## よくあるノートブックでの、LightGBMの実行例"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 142\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010727 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 3798\n[LightGBM] [Info] Number of data points in the train set: 379, number of used features: 30\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625330 -> initscore=0.512233\n[LightGBM] [Info] Start training from score 0.512233\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1]\ttrain's binary_logloss: 0.583245\tvalid's binary_logloss: 0.582221\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[2]\ttrain's binary_logloss: 0.518624\tvalid's binary_logloss: 0.519402\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[3]\ttrain's binary_logloss: 0.467531\tvalid's binary_logloss: 0.471914\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[4]\ttrain's binary_logloss: 0.423087\tvalid's binary_logloss: 0.426939\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[5]\ttrain's binary_logloss: 0.385211\tvalid's binary_logloss: 0.391658\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[6]\ttrain's binary_logloss: 0.349443\tvalid's binary_logloss: 0.356531\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[7]\ttrain's binary_logloss: 0.317067\tvalid's binary_logloss: 0.327033\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[8]\ttrain's binary_logloss: 0.289598\tvalid's binary_logloss: 0.299828\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[9]\ttrain's binary_logloss: 0.267131\tvalid's binary_logloss: 0.278931\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[10]\ttrain's binary_logloss: 0.245916\tvalid's binary_logloss: 0.258254\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[11]\ttrain's binary_logloss: 0.226934\tvalid's binary_logloss: 0.241703\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[12]\ttrain's binary_logloss: 0.210347\tvalid's binary_logloss: 0.22565\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[13]\ttrain's binary_logloss: 0.19611\tvalid's binary_logloss: 0.213778\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[14]\ttrain's binary_logloss: 0.181945\tvalid's binary_logloss: 0.197933\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[15]\ttrain's binary_logloss: 0.168331\tvalid's binary_logloss: 0.18491\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[16]\ttrain's binary_logloss: 0.157474\tvalid's binary_logloss: 0.176478\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[17]\ttrain's binary_logloss: 0.145925\tvalid's binary_logloss: 0.167553\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[18]\ttrain's binary_logloss: 0.135624\tvalid's binary_logloss: 0.157974\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[19]\ttrain's binary_logloss: 0.126928\tvalid's binary_logloss: 0.151323\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[20]\ttrain's binary_logloss: 0.11911\tvalid's binary_logloss: 0.144895\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[21]\ttrain's binary_logloss: 0.111022\tvalid's binary_logloss: 0.135649\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[22]\ttrain's binary_logloss: 0.103684\tvalid's binary_logloss: 0.12993\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[23]\ttrain's binary_logloss: 0.0962253\tvalid's binary_logloss: 0.123531\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[24]\ttrain's binary_logloss: 0.0896759\tvalid's binary_logloss: 0.117425\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[25]\ttrain's binary_logloss: 0.0838193\tvalid's binary_logloss: 0.111944\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[26]\ttrain's binary_logloss: 0.0785658\tvalid's binary_logloss: 0.107157\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[27]\ttrain's binary_logloss: 0.0736935\tvalid's binary_logloss: 0.101922\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[28]\ttrain's binary_logloss: 0.0681601\tvalid's binary_logloss: 0.100178\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[29]\ttrain's binary_logloss: 0.0634425\tvalid's binary_logloss: 0.0957191\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[30]\ttrain's binary_logloss: 0.0592376\tvalid's binary_logloss: 0.0930103\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[31]\ttrain's binary_logloss: 0.0554449\tvalid's binary_logloss: 0.0896791\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[32]\ttrain's binary_logloss: 0.0510206\tvalid's binary_logloss: 0.0879681\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[33]\ttrain's binary_logloss: 0.0471317\tvalid's binary_logloss: 0.0868479\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[34]\ttrain's binary_logloss: 0.0440876\tvalid's binary_logloss: 0.0822513\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[35]\ttrain's binary_logloss: 0.0407371\tvalid's binary_logloss: 0.0805727\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[36]\ttrain's binary_logloss: 0.03793\tvalid's binary_logloss: 0.0788549\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[37]\ttrain's binary_logloss: 0.0349672\tvalid's binary_logloss: 0.0761908\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[38]\ttrain's binary_logloss: 0.0326998\tvalid's binary_logloss: 0.0738255\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[39]\ttrain's binary_logloss: 0.0306578\tvalid's binary_logloss: 0.0698516\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[40]\ttrain's binary_logloss: 0.0283008\tvalid's binary_logloss: 0.0689386\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[41]\ttrain's binary_logloss: 0.0263106\tvalid's binary_logloss: 0.0671285\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[42]\ttrain's binary_logloss: 0.024677\tvalid's binary_logloss: 0.0644577\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[43]\ttrain's binary_logloss: 0.0229245\tvalid's binary_logloss: 0.0611481\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[44]\ttrain's binary_logloss: 0.0211353\tvalid's binary_logloss: 0.0579387\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[45]\ttrain's binary_logloss: 0.019486\tvalid's binary_logloss: 0.0570836\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[46]\ttrain's binary_logloss: 0.0179818\tvalid's binary_logloss: 0.0566918\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[47]\ttrain's binary_logloss: 0.0170773\tvalid's binary_logloss: 0.0560871\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[48]\ttrain's binary_logloss: 0.0157177\tvalid's binary_logloss: 0.0534724\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[49]\ttrain's binary_logloss: 0.0147924\tvalid's binary_logloss: 0.051641\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[50]\ttrain's binary_logloss: 0.013864\tvalid's binary_logloss: 0.050688\nAccuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "\n",
    "x, y = dataset.data, dataset.target\n",
    "# データセットを学習用とテスト用に分割する\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y,\n",
    "                                                    test_size=0.166,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "# さらに学習用データを学習用とvalid用に分割する\n",
    "tr_x, va_x, tr_y, va_y = train_test_split(train_x, train_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=train_y)\n",
    "# LightGBM が扱うデータセットの形式に直す\n",
    "dtrain = lgb.Dataset(tr_x, label=tr_y)\n",
    "dvalid = lgb.Dataset(va_x, label=va_y)\n",
    "dtest = lgb.Dataset(test_x)\n",
    "\n",
    "# 学習用のパラメータ\n",
    "lgb_params = {\n",
    "    # 二値分類問題\n",
    "    'objective': 'binary',\n",
    "    # 評価指標\n",
    "    'metrics': 'binary_logloss',\n",
    "}\n",
    "# モデルを学習する\n",
    "# バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "# watchlistには学習データおよびバリデーションデータをセットする\n",
    "#watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = lgb.train(lgb_params,\n",
    "                dtrain,\n",
    "                num_boost_round=50,  # 学習ラウンド数は適当\n",
    "                #evals=watchlist\n",
    "                valid_names=['train','valid'], valid_sets=[dtrain, dvalid]\n",
    "                )\n",
    "# 予測：検証用データが各クラスに分類される確率を計算する\n",
    "pred_proba = model.predict(test_x)\n",
    "# しきい値 0.5 で 0, 1 に丸める\n",
    "pred = np.where(pred_proba > 0.5, 1, 0)\n",
    "# 精度 (Accuracy) を検証する\n",
    "acc = accuracy_score(test_y, pred)\n",
    "print('Accuracy:', acc)\n"
   ]
  },
  {
   "source": [
    "## 1-1.データの保存"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "df = pd.DataFrame(np.append(data.data, data.target.reshape(-1,1), axis=1), columns=np.append(data.feature_names,\n",
    " 'target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(569, 31)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['target'] = int(df['target'])\n",
    "df = df.astype({'target': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(569, 31)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../input/breast_cancer.csv', index=False)"
   ]
  },
  {
   "source": [
    "## 1-2.データ分割"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = dataset.data, dataset.target\n",
    "x, y = df[data.feature_names], df['target']\n",
    "# データセットを学習用とテスト用に分割する\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y,\n",
    "                                                    test_size=0.166,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "# さらに学習用データを学習用とvalid用に分割する\n",
    "tr_x, va_x, tr_y, va_y = train_test_split(train_x, train_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(379, 30)\n(379,)\n(95, 30)\n(95,)\n(95, 30)\n(95,)\n"
     ]
    }
   ],
   "source": [
    "print(tr_x.shape)\n",
    "print(tr_y.shape)\n",
    "print(va_x.shape)\n",
    "print(va_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([tr_x,tr_y], axis=1).to_csv('../opt/ml/input/data/train/train.csv', index=False)\n",
    "pd.concat([va_x,va_y], axis=1).to_csv('../opt/ml/input/data/valid/valid.csv', index=False)\n",
    "pd.concat([test_x,test_y], axis=1).to_csv('../opt/ml/input/data/test/test.csv', index=False)"
   ]
  },
  {
   "source": [
    "## 1-3.学習"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM が扱うデータセットの形式に直す\n",
    "dtrain = lgb.Dataset(tr_x, label=tr_y)\n",
    "dvalid = lgb.Dataset(va_x, label=va_y)\n",
    "dtest = lgb.Dataset(test_x)\n",
    "\n",
    "# 学習用のパラメータ\n",
    "lgb_params = {\n",
    "    # 二値分類問題\n",
    "    'objective': 'binary',\n",
    "    # 評価指標\n",
    "    'metrics': 'binary_logloss',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 142\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3798\n",
      "[LightGBM] [Info] Number of data points in the train set: 379, number of used features: 30\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625330 -> initscore=0.512233\n",
      "[LightGBM] [Info] Start training from score 0.512233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's binary_logloss: 0.583245\tvalid's binary_logloss: 0.582221\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's binary_logloss: 0.518624\tvalid's binary_logloss: 0.519402\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's binary_logloss: 0.467531\tvalid's binary_logloss: 0.471914\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's binary_logloss: 0.423087\tvalid's binary_logloss: 0.426939\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's binary_logloss: 0.385211\tvalid's binary_logloss: 0.391658\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's binary_logloss: 0.349443\tvalid's binary_logloss: 0.356531\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's binary_logloss: 0.317067\tvalid's binary_logloss: 0.327033\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's binary_logloss: 0.289598\tvalid's binary_logloss: 0.299828\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's binary_logloss: 0.267131\tvalid's binary_logloss: 0.278931\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's binary_logloss: 0.245916\tvalid's binary_logloss: 0.258254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\ttrain's binary_logloss: 0.226934\tvalid's binary_logloss: 0.241703\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\ttrain's binary_logloss: 0.210347\tvalid's binary_logloss: 0.22565\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\ttrain's binary_logloss: 0.19611\tvalid's binary_logloss: 0.213778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\ttrain's binary_logloss: 0.181945\tvalid's binary_logloss: 0.197933\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\ttrain's binary_logloss: 0.168331\tvalid's binary_logloss: 0.18491\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\ttrain's binary_logloss: 0.157474\tvalid's binary_logloss: 0.176478\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\ttrain's binary_logloss: 0.145925\tvalid's binary_logloss: 0.167553\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\ttrain's binary_logloss: 0.135624\tvalid's binary_logloss: 0.157974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\ttrain's binary_logloss: 0.126928\tvalid's binary_logloss: 0.151323\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\ttrain's binary_logloss: 0.11911\tvalid's binary_logloss: 0.144895\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\ttrain's binary_logloss: 0.111022\tvalid's binary_logloss: 0.135649\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\ttrain's binary_logloss: 0.103684\tvalid's binary_logloss: 0.12993\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\ttrain's binary_logloss: 0.0962253\tvalid's binary_logloss: 0.123531\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\ttrain's binary_logloss: 0.0896759\tvalid's binary_logloss: 0.117425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\ttrain's binary_logloss: 0.0838193\tvalid's binary_logloss: 0.111944\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\ttrain's binary_logloss: 0.0785658\tvalid's binary_logloss: 0.107157\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\ttrain's binary_logloss: 0.0736935\tvalid's binary_logloss: 0.101922\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\ttrain's binary_logloss: 0.0681601\tvalid's binary_logloss: 0.100178\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\ttrain's binary_logloss: 0.0634425\tvalid's binary_logloss: 0.0957191\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\ttrain's binary_logloss: 0.0592376\tvalid's binary_logloss: 0.0930103\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\ttrain's binary_logloss: 0.0554449\tvalid's binary_logloss: 0.0896791\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\ttrain's binary_logloss: 0.0510206\tvalid's binary_logloss: 0.0879681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\ttrain's binary_logloss: 0.0471317\tvalid's binary_logloss: 0.0868479\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\ttrain's binary_logloss: 0.0440876\tvalid's binary_logloss: 0.0822513\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\ttrain's binary_logloss: 0.0407371\tvalid's binary_logloss: 0.0805727\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\ttrain's binary_logloss: 0.03793\tvalid's binary_logloss: 0.0788549\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\ttrain's binary_logloss: 0.0349672\tvalid's binary_logloss: 0.0761908\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\ttrain's binary_logloss: 0.0326998\tvalid's binary_logloss: 0.0738255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\ttrain's binary_logloss: 0.0306578\tvalid's binary_logloss: 0.0698516\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\ttrain's binary_logloss: 0.0283008\tvalid's binary_logloss: 0.0689386\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\ttrain's binary_logloss: 0.0263106\tvalid's binary_logloss: 0.0671285\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\ttrain's binary_logloss: 0.024677\tvalid's binary_logloss: 0.0644577\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\ttrain's binary_logloss: 0.0229245\tvalid's binary_logloss: 0.0611481\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\ttrain's binary_logloss: 0.0211353\tvalid's binary_logloss: 0.0579387\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\ttrain's binary_logloss: 0.019486\tvalid's binary_logloss: 0.0570836\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\ttrain's binary_logloss: 0.0179818\tvalid's binary_logloss: 0.0566918\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\ttrain's binary_logloss: 0.0170773\tvalid's binary_logloss: 0.0560871\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\ttrain's binary_logloss: 0.0157177\tvalid's binary_logloss: 0.0534724\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\ttrain's binary_logloss: 0.0147924\tvalid's binary_logloss: 0.051641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\ttrain's binary_logloss: 0.013864\tvalid's binary_logloss: 0.050688\n"
     ]
    }
   ],
   "source": [
    "# モデルを学習する\n",
    "# バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "# watchlistには学習データおよびバリデーションデータをセットする\n",
    "#watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = lgb.train(lgb_params,\n",
    "                dtrain,\n",
    "                num_boost_round=50,  # 学習ラウンド数は適当\n",
    "                #evals=watchlist\n",
    "                valid_names=['train','valid'], valid_sets=[dtrain, dvalid]\n",
    "                )"
   ]
  },
  {
   "source": [
    "## 1-4. 予測・評価"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# 予測：検証用データが各クラスに分類される確率を計算する\n",
    "pred_proba = model.predict(test_x)\n",
    "# しきい値 0.5 で 0, 1 に丸める\n",
    "pred = np.where(pred_proba > 0.5, 1, 0)\n",
    "# 精度 (Accuracy) を検証する\n",
    "acc = accuracy_score(test_y, pred)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.append(test_y.reshape(-1,1), pred.reshape(-1,1), axis=1), columns=['target', 'pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test_yがseriesの場合\n",
    "s_test_y = pd.Series(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "type(s_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.append(np.array(s_test_y).reshape(-1,1), pred.reshape(-1,1), axis=1), columns=['target', 'pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('../opt/ml/model/result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3') #S3オブジェクトを取得\n",
    "s3.meta.client.upload_file('../opt/ml/model/result.csv', 'work-aws-virginia', 'test-trainingjob/output/result.csv')\n",
    "\n",
    "#bucket = s3.Bucket('バケット名')\n",
    "#bucket.upload_file('/opt/ml/model/result.csv', '保存先S3のpath')"
   ]
  },
  {
   "source": [
    "## 2.ローカル環境で学習ジョブ風に実行する（コンテナ未使用）\n",
    "コンテナを導入する前に、ローカル環境でSageMaker学習ジョブのように動かします。.pyファイルの動作確認を高速で行うことが目的です。\n",
    "ディレクトリ構造"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2-1. データ配置"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([tr_x,tr_y], axis=1).to_csv('../opt/ml/input/data/train/train.csv', index=False)\n",
    "pd.concat([va_x,va_y], axis=1).to_csv('../opt/ml/input/data/valid/valid.csv', index=False)\n",
    "pd.concat([test_x,test_y], axis=1).to_csv('../opt/ml/input/data/test/test.csv', index=False)"
   ]
  },
  {
   "source": [
    "## 2-2. ソースコードを準備\n",
    "../opt/ml/input/data/src/train.pyに配置"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ../opt/program/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ../opt/ml/input/data/src/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[37m#!/usr/bin/env python\u001b[39;49;00m\n\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlightgbm\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mlgb\u001b[39;49;00m\n\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.metrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m accuracy_score\n\n\u001b[37m# データ読み込み\u001b[39;49;00m\ntrain_df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../opt/ml/input/data/train/train.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\nvalid_df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../opt/ml/input/data/valid/valid.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\ntest_df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../opt/ml/input/data/test/test.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n\ntr_x, tr_y = train_df.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m), train_df[\u001b[33m'\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\nva_x, va_y = valid_df.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m), valid_df[\u001b[33m'\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\ntest_x, test_y = test_df.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m), test_df[\u001b[33m'\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n\n\u001b[37m# 学習準備\u001b[39;49;00m\n\u001b[37m# LightGBM が扱うデータセットの形式に直す\u001b[39;49;00m\ndtrain = lgb.Dataset(tr_x, label=tr_y)\ndvalid = lgb.Dataset(va_x, label=va_y)\ndtest = lgb.Dataset(test_x)\n\n\u001b[37m# 学習用のパラメータ\u001b[39;49;00m\nlgb_params = {\n    \u001b[37m# 二値分類問題\u001b[39;49;00m\n    \u001b[33m'\u001b[39;49;00m\u001b[33mobjective\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mbinary\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n    \u001b[37m# 評価指標\u001b[39;49;00m\n    \u001b[33m'\u001b[39;49;00m\u001b[33mmetrics\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mbinary_logloss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n}\n\n\u001b[37m# 学習\u001b[39;49;00m\n\u001b[37m# モデルを学習する\u001b[39;49;00m\n\u001b[37m# バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\u001b[39;49;00m\n\u001b[37m# watchlistには学習データおよびバリデーションデータをセットする\u001b[39;49;00m\n\u001b[37m#watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\u001b[39;49;00m\nmodel = lgb.train(lgb_params,\n                dtrain,\n                num_boost_round=\u001b[34m50\u001b[39;49;00m,  \u001b[37m# 学習ラウンド数は適当\u001b[39;49;00m\n                \u001b[37m#evals=watchlist\u001b[39;49;00m\n                valid_names=[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mvalid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], valid_sets=[dtrain, dvalid]\n                )\n\u001b[37m# 予測\u001b[39;49;00m\n\u001b[37m# 予測：検証用データが各クラスに分類される確率を計算する\u001b[39;49;00m\npred_proba = model.predict(test_x)\n\u001b[37m# しきい値 0.5 で 0, 1 に丸める\u001b[39;49;00m\npred = np.where(pred_proba > \u001b[34m0.5\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m)\n\u001b[37m# 評価\u001b[39;49;00m\n\u001b[37m# 精度 (Accuracy) を検証する\u001b[39;49;00m\nacc = accuracy_score(test_y, pred)\n\u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mAccuracy:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, acc)\n\u001b[37m# 予測結果を出力\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ../opt/ml/input/data/src/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train running...\n",
      "/Users/yshiy/github/sagemaker-byoc/notebook\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 142\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3798\n",
      "[LightGBM] [Info] Number of data points in the train set: 379, number of used features: 30\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625330 -> initscore=0.512233\n",
      "[LightGBM] [Info] Start training from score 0.512233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's binary_logloss: 0.583245\tvalid's binary_logloss: 0.582221\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's binary_logloss: 0.518624\tvalid's binary_logloss: 0.519402\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's binary_logloss: 0.467531\tvalid's binary_logloss: 0.471914\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's binary_logloss: 0.423087\tvalid's binary_logloss: 0.426939\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's binary_logloss: 0.385211\tvalid's binary_logloss: 0.391658\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's binary_logloss: 0.349443\tvalid's binary_logloss: 0.356531\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's binary_logloss: 0.317067\tvalid's binary_logloss: 0.327033\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's binary_logloss: 0.289598\tvalid's binary_logloss: 0.299828\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's binary_logloss: 0.267131\tvalid's binary_logloss: 0.278931\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's binary_logloss: 0.245916\tvalid's binary_logloss: 0.258254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\ttrain's binary_logloss: 0.226934\tvalid's binary_logloss: 0.241703\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\ttrain's binary_logloss: 0.210347\tvalid's binary_logloss: 0.22565\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\ttrain's binary_logloss: 0.19611\tvalid's binary_logloss: 0.213778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\ttrain's binary_logloss: 0.181945\tvalid's binary_logloss: 0.197933\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\ttrain's binary_logloss: 0.168331\tvalid's binary_logloss: 0.18491\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\ttrain's binary_logloss: 0.157474\tvalid's binary_logloss: 0.176478\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\ttrain's binary_logloss: 0.145925\tvalid's binary_logloss: 0.167553\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\ttrain's binary_logloss: 0.135624\tvalid's binary_logloss: 0.157974\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\ttrain's binary_logloss: 0.126928\tvalid's binary_logloss: 0.151323\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\ttrain's binary_logloss: 0.11911\tvalid's binary_logloss: 0.144895\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\ttrain's binary_logloss: 0.111022\tvalid's binary_logloss: 0.135649\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\ttrain's binary_logloss: 0.103684\tvalid's binary_logloss: 0.12993\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\ttrain's binary_logloss: 0.0962253\tvalid's binary_logloss: 0.123531\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\ttrain's binary_logloss: 0.0896759\tvalid's binary_logloss: 0.117425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\ttrain's binary_logloss: 0.0838193\tvalid's binary_logloss: 0.111944\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\ttrain's binary_logloss: 0.0785658\tvalid's binary_logloss: 0.107157\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\ttrain's binary_logloss: 0.0736935\tvalid's binary_logloss: 0.101922\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\ttrain's binary_logloss: 0.0681601\tvalid's binary_logloss: 0.100178\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\ttrain's binary_logloss: 0.0634425\tvalid's binary_logloss: 0.0957191\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\ttrain's binary_logloss: 0.0592376\tvalid's binary_logloss: 0.0930103\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\ttrain's binary_logloss: 0.0554449\tvalid's binary_logloss: 0.0896791\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\ttrain's binary_logloss: 0.0510206\tvalid's binary_logloss: 0.0879681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\ttrain's binary_logloss: 0.0471317\tvalid's binary_logloss: 0.0868479\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\ttrain's binary_logloss: 0.0440876\tvalid's binary_logloss: 0.0822513\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\ttrain's binary_logloss: 0.0407371\tvalid's binary_logloss: 0.0805727\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\ttrain's binary_logloss: 0.03793\tvalid's binary_logloss: 0.0788549\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\ttrain's binary_logloss: 0.0349672\tvalid's binary_logloss: 0.0761908\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\ttrain's binary_logloss: 0.0326998\tvalid's binary_logloss: 0.0738255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\ttrain's binary_logloss: 0.0306578\tvalid's binary_logloss: 0.0698516\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\ttrain's binary_logloss: 0.0283008\tvalid's binary_logloss: 0.0689386\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\ttrain's binary_logloss: 0.0263106\tvalid's binary_logloss: 0.0671285\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\ttrain's binary_logloss: 0.024677\tvalid's binary_logloss: 0.0644577\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\ttrain's binary_logloss: 0.0229245\tvalid's binary_logloss: 0.0611481\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\ttrain's binary_logloss: 0.0211353\tvalid's binary_logloss: 0.0579387\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\ttrain's binary_logloss: 0.019486\tvalid's binary_logloss: 0.0570836\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\ttrain's binary_logloss: 0.0179818\tvalid's binary_logloss: 0.0566918\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\ttrain's binary_logloss: 0.0170773\tvalid's binary_logloss: 0.0560871\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\ttrain's binary_logloss: 0.0157177\tvalid's binary_logloss: 0.0534724\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\ttrain's binary_logloss: 0.0147924\tvalid's binary_logloss: 0.051641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\ttrain's binary_logloss: 0.013864\tvalid's binary_logloss: 0.050688\n",
      "Accuracy: 0.9473684210526315\n",
      "train end\n"
     ]
    }
   ],
   "source": [
    "!../opt/program/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# 3.ローカルモードで学習ジョブを実行"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### ---------------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.コンテナ準備\n",
    "## 1-1.Dockerfile (確認のみ)\n",
    "\n",
    "Dockerfileには、構築したいイメージが記述されています。これは、実行したいシステムの完全なオペレーティングシステムのインストールを記述していると考えることができます。しかし、Dockerコンテナの実行は、基本的な操作のためにホストマシン上のLinuxを利用するため、完全なオペレーティングシステムよりもかなり軽量です。\n",
    "\n",
    "Pythonサイエンススタックでは、標準的なUbuntuのインストールから始めて、通常のツールを実行してscikit-learnで必要なものをインストールします。最後に、特定のアルゴリズムを実装したコードをコンテナに追加して、実行に適した環境を整えます。\n",
    "\n",
    "その際、余分なスペースを整理します。これにより、コンテナは小さくなり、起動も速くなります。\n",
    "\n",
    "例のDockerfileを見てみましょう。"
   ]
  },
  {
   "source": [
    "imageには、trainやbacktestに必要なソースは含めないこととする。\n",
    "（学習ジョブ実行時にS3からコピーする）\n",
    "よって、dockerイメージ作成時に必要な資材はない。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FROM python:3.7.5-slim\nUSER root\n\nRUN apt-get update\nRUN apt-get -y install locales && \\\n    localedef -f UTF-8 -i ja_JP ja_JP.UTF-8\nENV LANG ja_JP.UTF-8\nENV LANGUAGE ja_JP:ja\nENV LC_ALL ja_JP.UTF-8\nENV TZ JST-9\nENV TERM xterm\n\nRUN apt-get install -y vim less\nRUN pip install --upgrade pip\nRUN pip install --upgrade setuptools\n\nRUN apt-get -y install build-essential\nRUN apt-get -y install wget\n\n### install libraries\nRUN pip install numpy pandas scikit-learn matplotlib seaborn lightgbm boto3\n\n# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\n# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\n# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\n# PATH so that the train and serve programs are found when the container is invoked.\n\nENV PYTHONUNBUFFERED=TRUE\nENV PYTHONDONTWRITEBYTECODE=TRUE\nENV PATH=\"/opt/program:${PATH}\"\n\n# Set up the program in the image\nCOPY program /opt/program\nWORKDIR /opt/program"
     ]
    }
   ],
   "source": [
    "!cat ../container/lgbm/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2.Building and registering the container to ECR\n",
    "\n",
    "以下のシェルコードは、`docker build`を使用してコンテナイメージをビルドし、`docker push`を使用してコンテナイメージをECRにプッシュする方法を示しています。このコードはシェルスクリプト `container/build-and-push.sh` としても提供されており、`build-and-push.sh decision_trees_sample` として実行することで、イメージ `decision_trees_sample` をビルドすることができます。\n",
    "\n",
    "このコードは、使用しているアカウントと現在のデフォルトリージョン（SageMakerのノートブックインスタンスを使用している場合は、ノートブックインスタンスが作成されたリージョンになります）でECRリポジトリを探します。\n",
    "リポジトリが存在しない場合、スクリプトはそれを作成します。"
   ]
  },
  {
   "source": [
    "https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/container/build_and_push.sh\n",
    "\n",
    "以下は、build-and-push.shと同じ内容"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Login Succeeded\n",
      "\n",
      "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n",
      "The push refers to repository [805433377179.dkr.ecr.us-east-1.amazonaws.com/test-trainingjob]\n",
      "5f70bf18a086: Preparing\n",
      "cf45398a159b: Preparing\n",
      "79a667ff6c52: Preparing\n",
      "f3b1d227f587: Preparing\n",
      "adcb570b8c76: Preparing\n",
      "6accb6f2a916: Preparing\n",
      "c4faa9f0fb36: Preparing\n",
      "c84816008bc0: Preparing\n",
      "6e7f4419aa67: Preparing\n",
      "5c920f5933f2: Preparing\n",
      "36c21e895230: Preparing\n",
      "870ea4318145: Preparing\n",
      "ca56b6fe98b7: Preparing\n",
      "459d9d53a256: Preparing\n",
      "831c5620387f: Preparing\n",
      "6e7f4419aa67: Waiting\n",
      "5c920f5933f2: Waiting\n",
      "36c21e895230: Waiting\n",
      "870ea4318145: Waiting\n",
      "ca56b6fe98b7: Waiting\n",
      "459d9d53a256: Waiting\n",
      "831c5620387f: Waiting\n",
      "6accb6f2a916: Waiting\n",
      "c4faa9f0fb36: Waiting\n",
      "c84816008bc0: Waiting\n",
      "5f70bf18a086: Layer already exists\n",
      "adcb570b8c76: Layer already exists\n",
      "f3b1d227f587: Layer already exists\n",
      "6accb6f2a916: Layer already exists\n",
      "c84816008bc0: Layer already exists\n",
      "c4faa9f0fb36: Layer already exists\n",
      "6e7f4419aa67: Layer already exists\n",
      "36c21e895230: Layer already exists\n",
      "5c920f5933f2: Layer already exists\n",
      "870ea4318145: Layer already exists\n",
      "ca56b6fe98b7: Layer already exists\n",
      "459d9d53a256: Layer already exists\n",
      "cf45398a159b: Pushed\n",
      "831c5620387f: Layer already exists\n",
      "79a667ff6c52: Pushed\n",
      "latest: digest: sha256:10d568fee73f501eef9a2ffb1f649dd34f80a89d4b8ff48cae058a539f71d29b size: 3476\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 sha256:9add0e49026b488e6c5675406bc6d3f35a20b91082baae3566f9c39b1828dff0\n",
      "#1 transferring dockerfile: 1.09kB 0.0s done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load .dockerignore\n",
      "#2 sha256:33086c0a9a19f953a7d49596fe408fac0f4d7296d4964763631c685941bf7bdc\n",
      "#2 transferring context:\n",
      "#2 transferring context: 2B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/library/python:3.7.5-slim\n",
      "#3 sha256:22b63656d419fcba694489b15d89c5feef3d46867e4e24af032886a8747595e3\n",
      "#3 DONE 2.0s\n",
      "\n",
      "#4 [ 1/11] FROM docker.io/library/python:3.7.5-slim@sha256:59af1bb7fb92ff97c9a23abae23f6beda13a95dbfd8100c7a2f71d150c0dc6e5\n",
      "#4 sha256:fc4998b781e13a5831b9eedd506704f9826ce3e9c19f6f5ce3412b691f20e1d8\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#10 [ 7/11] RUN apt-get -y install build-essential\n",
      "#10 sha256:69d98b54efc55ce868296272d29d7d9ab8225bd33598f22a44b0d525e8125004\n",
      "#10 CACHED\n",
      "\n",
      "#7 [ 4/11] RUN apt-get install -y vim less\n",
      "#7 sha256:523ab75464fa1d25fafee4fe5157d03324d5acf56ac878450b2a21125a99c7f3\n",
      "#7 CACHED\n",
      "\n",
      "#6 [ 3/11] RUN apt-get -y install locales &&     localedef -f UTF-8 -i ja_JP ja_JP.UTF-8\n",
      "#6 sha256:0ec4b58f047414e2eb9732f4162e0d29a40b21a1c0d7ff8378cd5e935adb68f0\n",
      "#6 CACHED\n",
      "\n",
      "#8 [ 5/11] RUN pip install --upgrade pip\n",
      "#8 sha256:380e3ba9e4aa0e0d78433de4df458261aab910eed2bdf44bd801820991eb0395\n",
      "#8 CACHED\n",
      "\n",
      "#9 [ 6/11] RUN pip install --upgrade setuptools\n",
      "#9 sha256:923040beadcd250867e6389781d9a95b93e1a985ecb6eb3d5f7c311fe3197af5\n",
      "#9 CACHED\n",
      "\n",
      "#5 [ 2/11] RUN apt-get update\n",
      "#5 sha256:2491597e2b4770a20c5941b870cd7018bef0b6847670a57e6190c5fcc79bbd02\n",
      "#5 CACHED\n",
      "\n",
      "#11 [ 8/11] RUN apt-get -y install wget\n",
      "#11 sha256:aae72b27815d154a97e407c8310d10994f9dec83ff7e4380c85177caa20eb7b6\n",
      "#11 CACHED\n",
      "\n",
      "#13 [internal] load build context\n",
      "#13 sha256:dd010c9e7f101bad37c677c660f536adcfcc40bb586efd1ec440fae50ab42282\n",
      "#13 transferring context: 61B done\n",
      "#13 DONE 0.0s\n",
      "\n",
      "#12 [ 9/11] RUN pip install numpy pandas scikit-learn matplotlib seaborn lightgbm boto3\n",
      "#12 sha256:4e3a6b74defd33ccacae4d22f240aff6b7486e016d4e30007c2a621122df0d00\n",
      "#12 1.580 WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "#12 1.580 distutils: /usr/local/include/python3.7m/UNKNOWN\n",
      "#12 1.580 sysconfig: /usr/local/include/python3.7m\n",
      "#12 1.580 WARNING: Additional context:\n",
      "#12 1.580 user = False\n",
      "#12 1.580 home = None\n",
      "#12 1.580 root = None\n",
      "#12 1.580 prefix = None\n",
      "#12 2.736 Collecting numpy\n",
      "#12 2.857   Downloading numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3 MB)\n",
      "#12 9.200 Collecting pandas\n",
      "#12 9.222   WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/51/51/48f3fc47c4e2144da2806dfb6629c4dd1fa3d5a143f9652b141e979a8ca9/pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl\n",
      "#12 9.338   Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "#12 12.67 Collecting scikit-learn\n",
      "#12 12.74   Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "#12 20.14 Collecting matplotlib\n",
      "#12 20.28   Downloading matplotlib-3.4.2-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
      "#12 22.88 Collecting seaborn\n",
      "#12 22.92   Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
      "#12 23.19 Collecting lightgbm\n",
      "#12 23.38   Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "#12 25.77 Collecting boto3\n",
      "#12 25.82   Downloading boto3-1.17.82-py2.py3-none-any.whl (131 kB)\n",
      "#12 26.35 Collecting pytz>=2017.3\n",
      "#12 26.38   Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "#12 26.54 Collecting python-dateutil>=2.7.3\n",
      "#12 26.57   Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "#12 26.70 Collecting six>=1.5\n",
      "#12 26.72   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "#12 26.81 Collecting threadpoolctl>=2.0.0\n",
      "#12 26.83   Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "#12 27.29 Collecting scipy>=0.19.1\n",
      "#12 27.33   Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "#12 35.97 Collecting joblib>=0.11\n",
      "#12 36.02   Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "#12 36.17 Collecting cycler>=0.10\n",
      "#12 36.19   Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "#12 36.39 Collecting pyparsing>=2.2.1\n",
      "#12 36.42   Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "#12 36.54 Collecting kiwisolver>=1.0.1\n",
      "#12 36.60   Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "#12 37.66 Collecting pillow>=6.2.0\n",
      "#12 37.68   Downloading Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
      "#12 38.34 Requirement already satisfied: wheel in /usr/local/lib/python3.7/site-packages (from lightgbm) (0.33.6)\n",
      "#12 38.40 Collecting jmespath<1.0.0,>=0.7.1\n",
      "#12 38.43   Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "#12 39.84 Collecting botocore<1.21.0,>=1.20.82\n",
      "#12 39.88   Downloading botocore-1.20.82-py2.py3-none-any.whl (7.6 MB)\n",
      "#12 42.08 Collecting s3transfer<0.5.0,>=0.4.0\n",
      "#12 42.11   Downloading s3transfer-0.4.2-py2.py3-none-any.whl (79 kB)\n",
      "#12 42.26 Collecting urllib3<1.27,>=1.25.4\n",
      "#12 42.29   Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
      "#12 43.00 Installing collected packages: six, urllib3, python-dateutil, numpy, jmespath, threadpoolctl, scipy, pytz, pyparsing, pillow, kiwisolver, joblib, cycler, botocore, scikit-learn, s3transfer, pandas, matplotlib, seaborn, lightgbm, boto3\n",
      "#12 70.74 WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "#12 70.74 distutils: /usr/local/include/python3.7m/UNKNOWN\n",
      "#12 70.74 sysconfig: /usr/local/include/python3.7m\n",
      "#12 70.74 WARNING: Additional context:\n",
      "#12 70.74 user = False\n",
      "#12 70.74 home = None\n",
      "#12 70.74 root = None\n",
      "#12 70.74 prefix = None\n",
      "#12 70.75 WARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "#12 70.75 Successfully installed boto3-1.17.82 botocore-1.20.82 cycler-0.10.0 jmespath-0.10.0 joblib-1.0.1 kiwisolver-1.3.1 lightgbm-3.2.1 matplotlib-3.4.2 numpy-1.20.3 pandas-1.2.4 pillow-8.2.0 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2021.1 s3transfer-0.4.2 scikit-learn-0.24.2 scipy-1.6.3 seaborn-0.11.1 six-1.16.0 threadpoolctl-2.1.0 urllib3-1.26.5\n",
      "#12 70.98 WARNING: You are using pip version 21.1; however, version 21.1.2 is available.\n",
      "#12 70.98 You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "#12 DONE 71.5s\n",
      "\n",
      "#14 [10/11] COPY program /opt/program\n",
      "#14 sha256:e52a2ab5dc5f056bed52e76b7d2a7a43dd5af6f1c7a09a415c97fb49e31ac019\n",
      "#14 DONE 0.1s\n",
      "\n",
      "#15 [11/11] WORKDIR /opt/program\n",
      "#15 sha256:e0e6b8ccd4e21a37fa2005c28e93acc36629336c64129a8e8a0fdc14e4391095\n",
      "#15 DONE 0.0s\n",
      "\n",
      "#16 exporting to image\n",
      "#16 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00\n",
      "#16 exporting layers\n",
      "#16 exporting layers 10.2s done\n",
      "#16 writing image sha256:636217adc2a7f4985c5fceb0bba72b3e44d5f9f2ec6d221ab09fb97c48269931 done\n",
      "#16 naming to docker.io/library/test-trainingjob done\n",
      "#16 DONE 10.2s\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=test-trainingjob\n",
    "\n",
    "cd ../container/lgbm\n",
    "\n",
    "chmod +x program/train\n",
    "#chmod +x decision_trees/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "source": [
    "## 疑問：build and push したイメージの動作確認はローカルでできる？\n",
    "できる。ローカルモード"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# -----コンテナ準備完了-----"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. データとプログラムをS3にアップロード\n",
    "・SageMaker　SDKを使う場合。  \n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/utility/session.html\n",
    "\n",
    "\n",
    "・boto3でs3クライアントを使う場合。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "sess = sage.Session()\n",
    "\n",
    "# S3 prefix\n",
    "#prefix = 'DEMO-scikit-byo-iris'\n",
    "prefix = 'test-trainingjob/src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORK_DIRECTORY = 'data'\n",
    "#data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)\n",
    "\n",
    "train_location = sess.upload_data('../opt/ml/input/data/train', bucket='work-aws-virginia', key_prefix='test-trainingjob/train')\n",
    "valid_location = sess.upload_data('../opt/ml/input/data/valid', bucket='work-aws-virginia', key_prefix='test-trainingjob/valid')\n",
    "test_location = sess.upload_data('../opt/ml/input/data/test', bucket='work-aws-virginia', key_prefix='test-trainingjob/test')\n",
    "src_location = sess.upload_data('../opt/ml/input/data/src', bucket='work-aws-virginia', key_prefix='test-trainingjob/src')"
   ]
  },
  {
   "source": [
    "# -----データ準備完了-----"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1.学習ジョブ発行(ローカルモード)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_location = 's3://work-aws-virginia/test-rd/candles/'\n",
    "data_location = 's3://work-aws-virginia/test-trainingjob/train/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "#image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-decision-trees:latest'.format(account, region)\n",
    "\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/test-trainingjob:latest'.format(account, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'805433377179.dkr.ecr.us-east-1.amazonaws.com/test-trainingjob:latest'"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'candle_window': 15,\n",
    "                 'horizon': 300,\n",
    "                 'target': 'tgt_diff'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = 'arn:aws:iam::805433377179:role/sagemaker-sdk-for-local'\n",
    "\n",
    "lgbm = sage.estimator.Estimator(image_uri=image,\n",
    "                                #entasdfdfry_point1='run.sh',\n",
    "                                #source_sddddddddddir='src',\n",
    "                                role=role, \n",
    "                                instance_count=1,\n",
    "                                instance_type='local',\n",
    "                                #instance_type='ml.c4.2xlarge',\n",
    "                                output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                                hyperparameters=hyperparameters,\n",
    "                                #sagemaker_session=sess)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating ow2fcchm91-algo-1-mzkfs ... \n",
      "Creating ow2fcchm91-algo-1-mzkfs ... done\n",
      "Docker Compose is now in the Docker CLI, try `docker compose up`\n",
      "\n",
      "Attaching to ow2fcchm91-algo-1-mzkfs\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Info] Number of positive: 237, number of negative: 142\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003461 seconds.\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m You can set `force_col_wise=true` to remove the overhead.\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Info] Total Bins 3798\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Info] Number of data points in the train set: 379, number of used features: 30\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625330 -> initscore=0.512233\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Info] Start training from score 0.512233\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [1]\ttrain's binary_logloss: 0.583245\tvalid's binary_logloss: 0.582221\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [2]\ttrain's binary_logloss: 0.518624\tvalid's binary_logloss: 0.519402\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [3]\ttrain's binary_logloss: 0.467531\tvalid's binary_logloss: 0.471914\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [4]\ttrain's binary_logloss: 0.423087\tvalid's binary_logloss: 0.426939\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [5]\ttrain's binary_logloss: 0.385211\tvalid's binary_logloss: 0.391658\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [6]\ttrain's binary_logloss: 0.349443\tvalid's binary_logloss: 0.356531\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [7]\ttrain's binary_logloss: 0.317067\tvalid's binary_logloss: 0.327033\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [8]\ttrain's binary_logloss: 0.289598\tvalid's binary_logloss: 0.299828\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [9]\ttrain's binary_logloss: 0.267131\tvalid's binary_logloss: 0.278931\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [10]\ttrain's binary_logloss: 0.245916\tvalid's binary_logloss: 0.258254\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [11]\ttrain's binary_logloss: 0.226934\tvalid's binary_logloss: 0.241703\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [12]\ttrain's binary_logloss: 0.210347\tvalid's binary_logloss: 0.22565\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [13]\ttrain's binary_logloss: 0.19611\tvalid's binary_logloss: 0.213778\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [14]\ttrain's binary_logloss: 0.181945\tvalid's binary_logloss: 0.197933\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [15]\ttrain's binary_logloss: 0.168331\tvalid's binary_logloss: 0.18491\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [16]\ttrain's binary_logloss: 0.157474\tvalid's binary_logloss: 0.176478\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [17]\ttrain's binary_logloss: 0.145925\tvalid's binary_logloss: 0.167553\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [18]\ttrain's binary_logloss: 0.135624\tvalid's binary_logloss: 0.157974\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [19]\ttrain's binary_logloss: 0.126928\tvalid's binary_logloss: 0.151323\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [20]\ttrain's binary_logloss: 0.11911\tvalid's binary_logloss: 0.144895\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [21]\ttrain's binary_logloss: 0.111022\tvalid's binary_logloss: 0.135649\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [22]\ttrain's binary_logloss: 0.103684\tvalid's binary_logloss: 0.12993\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [23]\ttrain's binary_logloss: 0.0962253\tvalid's binary_logloss: 0.123531\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [24]\ttrain's binary_logloss: 0.0896759\tvalid's binary_logloss: 0.117425\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [25]\ttrain's binary_logloss: 0.0838193\tvalid's binary_logloss: 0.111944\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [26]\ttrain's binary_logloss: 0.0785658\tvalid's binary_logloss: 0.107157\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [27]\ttrain's binary_logloss: 0.0736935\tvalid's binary_logloss: 0.101922\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [28]\ttrain's binary_logloss: 0.0681601\tvalid's binary_logloss: 0.100178\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [29]\ttrain's binary_logloss: 0.0634425\tvalid's binary_logloss: 0.0957191\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [30]\ttrain's binary_logloss: 0.0592376\tvalid's binary_logloss: 0.0930103\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [31]\ttrain's binary_logloss: 0.0554449\tvalid's binary_logloss: 0.0896791\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [32]\ttrain's binary_logloss: 0.0510206\tvalid's binary_logloss: 0.0879681\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [33]\ttrain's binary_logloss: 0.0471317\tvalid's binary_logloss: 0.0868479\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [34]\ttrain's binary_logloss: 0.0440876\tvalid's binary_logloss: 0.0822513\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [35]\ttrain's binary_logloss: 0.0407371\tvalid's binary_logloss: 0.0805727\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [36]\ttrain's binary_logloss: 0.03793\tvalid's binary_logloss: 0.0788549\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [37]\ttrain's binary_logloss: 0.0349672\tvalid's binary_logloss: 0.0761908\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [38]\ttrain's binary_logloss: 0.0326998\tvalid's binary_logloss: 0.0738255\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [39]\ttrain's binary_logloss: 0.0306578\tvalid's binary_logloss: 0.0698516\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [40]\ttrain's binary_logloss: 0.0283008\tvalid's binary_logloss: 0.0689386\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [41]\ttrain's binary_logloss: 0.0263106\tvalid's binary_logloss: 0.0671285\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [42]\ttrain's binary_logloss: 0.024677\tvalid's binary_logloss: 0.0644577\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [43]\ttrain's binary_logloss: 0.0229245\tvalid's binary_logloss: 0.0611481\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [44]\ttrain's binary_logloss: 0.0211353\tvalid's binary_logloss: 0.0579387\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [45]\ttrain's binary_logloss: 0.019486\tvalid's binary_logloss: 0.0570836\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [46]\ttrain's binary_logloss: 0.0179818\tvalid's binary_logloss: 0.0566918\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [47]\ttrain's binary_logloss: 0.0170773\tvalid's binary_logloss: 0.0560871\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [48]\ttrain's binary_logloss: 0.0157177\tvalid's binary_logloss: 0.0534724\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [49]\ttrain's binary_logloss: 0.0147924\tvalid's binary_logloss: 0.051641\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m [50]\ttrain's binary_logloss: 0.013864\tvalid's binary_logloss: 0.050688\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs |\u001b[0m Accuracy: 0.9473684210526315\n",
      "\u001b[36mow2fcchm91-algo-1-mzkfs exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "lgbm.fit({'train':'s3://work-aws-virginia/test-trainingjob/train/',\n",
    "          'valid':'s3://work-aws-virginia/test-trainingjob/valid/',\n",
    "          'test' :'s3://work-aws-virginia/test-trainingjob/test/',\n",
    "          'src':'s3://work-aws-virginia/test-trainingjob/src/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# 3-2.学習ジョブ発行(SageMaker)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 下準備"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "sess = sage.Session()\n",
    "\n",
    "prefix = 'test-trainingjob/src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'timeframe': 15, 'horizon': 300, 'hist_row': 2}\n"
     ]
    }
   ],
   "source": [
    "### ソースコードをアップロード\n",
    "src_location = sess.upload_data('../opt/ml/input/data/src', bucket='work-aws-virginia', key_prefix=prefix)\n",
    "\n",
    "### ハイパーパラメータ設定（ローカルファイルから読み込み）\n",
    "hyperparameters={\"timeframe\": 15,\n",
    "                 \"horizon\" : 300,\n",
    "                 \"hist_row\" : 2\n",
    "}\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'opt/ml/input/config/hyperparameters.json'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-d9c71283c4ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### ハイパーパラメータ設定（ローカルファイルから読み込み）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHYPERPARAMETER_JSON_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'opt/ml/input/config/hyperparameters.json'"
     ]
    }
   ],
   "source": [
    "HYPERPARAMETER_JSON_PATH = \"../../../../../opt/ml/input/config/hyperparameters.json\"\n",
    "HYPERPARAMETER_JSON_PATH = \"opt/ml/input/config/hyperparameters.json\"\n",
    "\n",
    "import json\n",
    "### ハイパーパラメータ設定（ローカルファイルから読み込み）\n",
    "with open(HYPERPARAMETER_JSON_PATH, \"r\") as f:\n",
    "    hyperparameters = json.load(f)\n",
    "\n",
    "print(hyperparameters)"
   ]
  },
  {
   "source": [
    "## processingはhyperparameter使えたか？"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = 'arn:aws:iam::805433377179:role/sagemaker-sdk-for-local'\n",
    "#role = 'arn:aws:iam::805433377179:role/service-role/AmazonSageMaker-ExecutionRole-20191212T111531'\n",
    "\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/test-trainingjob:latest'.format(account, region)\n",
    "\n",
    "lgbm = sage.estimator.Estimator(image_uri=image,\n",
    "                                #entasdfdfry_point1='run.sh',　### 存在しない引数を指定しても通ってします。\n",
    "                                #source_sddddddddddir='src',\n",
    "                                role=role, \n",
    "                                instance_count=1,\n",
    "                                #instance_type='local',\n",
    "                                instance_type='ml.c4.2xlarge',\n",
    "                                #output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                                output_path='s3://work-aws-virginia/test-trainingjob/output/',\n",
    "                                #sagemaker_session=sess # ノートブックインスタンスで実行する場合にIAMを渡す\n",
    "                                hyperparameters=hyperparameters,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-27 14:24:18 Starting - Starting the training job...\n",
      "2021-05-27 14:24:41 Starting - Launching requested ML instancesProfilerReport-1622125457: InProgress\n",
      "......\n",
      "2021-05-27 14:25:41 Starting - Preparing the instances for training......\n",
      "2021-05-27 14:27:01 Downloading - Downloading input data\n",
      "2021-05-27 14:27:01 Training - Downloading the training image...\n",
      "2021-05-27 14:27:33 Uploading - Uploading generated training model\n",
      "2021-05-27 14:27:33 Completed - Training job completed\n",
      "\u001b[34m[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of positive: 237, number of negative: 142\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002047 seconds.\u001b[0m\n",
      "\u001b[34mYou can set `force_row_wise=true` to remove the overhead.\u001b[0m\n",
      "\u001b[34mAnd if memory is not enough, you can set `force_col_wise=true`.\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Total Bins 3798\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Number of data points in the train set: 379, number of used features: 30\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625330 -> initscore=0.512233\u001b[0m\n",
      "\u001b[34m[LightGBM] [Info] Start training from score 0.512233\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[1]#011train's binary_logloss: 0.583245#011valid's binary_logloss: 0.582221\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[2]#011train's binary_logloss: 0.518624#011valid's binary_logloss: 0.519402\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[3]#011train's binary_logloss: 0.467531#011valid's binary_logloss: 0.471914\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[4]#011train's binary_logloss: 0.423087#011valid's binary_logloss: 0.426939\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[5]#011train's binary_logloss: 0.385211#011valid's binary_logloss: 0.391658\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[6]#011train's binary_logloss: 0.349443#011valid's binary_logloss: 0.356531\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[7]#011train's binary_logloss: 0.317067#011valid's binary_logloss: 0.327033\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[8]#011train's binary_logloss: 0.289598#011valid's binary_logloss: 0.299828\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[9]#011train's binary_logloss: 0.267131#011valid's binary_logloss: 0.278931\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[10]#011train's binary_logloss: 0.245916#011valid's binary_logloss: 0.258254\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[11]#011train's binary_logloss: 0.226934#011valid's binary_logloss: 0.241703\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[12]#011train's binary_logloss: 0.210347#011valid's binary_logloss: 0.22565\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[13]#011train's binary_logloss: 0.19611#011valid's binary_logloss: 0.213778\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[14]#011train's binary_logloss: 0.181945#011valid's binary_logloss: 0.197933\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[15]#011train's binary_logloss: 0.168331#011valid's binary_logloss: 0.18491\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[16]#011train's binary_logloss: 0.157474#011valid's binary_logloss: 0.176478\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[17]#011train's binary_logloss: 0.145925#011valid's binary_logloss: 0.167553\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[18]#011train's binary_logloss: 0.135624#011valid's binary_logloss: 0.157974\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[19]#011train's binary_logloss: 0.126928#011valid's binary_logloss: 0.151323\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[20]#011train's binary_logloss: 0.11911#011valid's binary_logloss: 0.144895\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[21]#011train's binary_logloss: 0.111022#011valid's binary_logloss: 0.135649\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[22]#011train's binary_logloss: 0.103684#011valid's binary_logloss: 0.12993\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[23]#011train's binary_logloss: 0.0962253#011valid's binary_logloss: 0.123531\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[24]#011train's binary_logloss: 0.0896759#011valid's binary_logloss: 0.117425\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[25]#011train's binary_logloss: 0.0838193#011valid's binary_logloss: 0.111944\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[26]#011train's binary_logloss: 0.0785658#011valid's binary_logloss: 0.107157\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[27]#011train's binary_logloss: 0.0736935#011valid's binary_logloss: 0.101922\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[28]#011train's binary_logloss: 0.0681601#011valid's binary_logloss: 0.100178\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[29]#011train's binary_logloss: 0.0634425#011valid's binary_logloss: 0.0957191\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[30]#011train's binary_logloss: 0.0592376#011valid's binary_logloss: 0.0930103\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[31]#011train's binary_logloss: 0.0554449#011valid's binary_logloss: 0.0896791\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[32]#011train's binary_logloss: 0.0510206#011valid's binary_logloss: 0.0879681\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[33]#011train's binary_logloss: 0.0471317#011valid's binary_logloss: 0.0868479\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[34]#011train's binary_logloss: 0.0440876#011valid's binary_logloss: 0.0822513\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[35]#011train's binary_logloss: 0.0407371#011valid's binary_logloss: 0.0805727\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[36]#011train's binary_logloss: 0.03793#011valid's binary_logloss: 0.0788549\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[37]#011train's binary_logloss: 0.0349672#011valid's binary_logloss: 0.0761908\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[38]#011train's binary_logloss: 0.0326998#011valid's binary_logloss: 0.0738255\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[39]#011train's binary_logloss: 0.0306578#011valid's binary_logloss: 0.0698516\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[40]#011train's binary_logloss: 0.0283008#011valid's binary_logloss: 0.0689386\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[41]#011train's binary_logloss: 0.0263106#011valid's binary_logloss: 0.0671285\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[42]#011train's binary_logloss: 0.024677#011valid's binary_logloss: 0.0644577\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[43]#011train's binary_logloss: 0.0229245#011valid's binary_logloss: 0.0611481\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[44]#011train's binary_logloss: 0.0211353#011valid's binary_logloss: 0.0579387\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[45]#011train's binary_logloss: 0.019486#011valid's binary_logloss: 0.0570836\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[46]#011train's binary_logloss: 0.0179818#011valid's binary_logloss: 0.0566918\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[47]#011train's binary_logloss: 0.0170773#011valid's binary_logloss: 0.0560871\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[48]#011train's binary_logloss: 0.0157177#011valid's binary_logloss: 0.0534724\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[49]#011train's binary_logloss: 0.0147924#011valid's binary_logloss: 0.051641\u001b[0m\n",
      "\u001b[34m[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\u001b[0m\n",
      "\u001b[34m[50]#011train's binary_logloss: 0.013864#011valid's binary_logloss: 0.050688\u001b[0m\n",
      "\u001b[34mAccuracy: 0.9473684210526315\u001b[0m\n",
      "Training seconds: 62\n",
      "Billable seconds: 62\n"
     ]
    }
   ],
   "source": [
    "for\n",
    "                                hyperparameters=hyperparameters,\n",
    "\n",
    "\n",
    "lgbm = sage.estimator.Estimator\n",
    "\n",
    "lgbm.fit({'train':'s3://work-aws-virginia/test-trainingjob/train/',\n",
    "          'valid':'s3://work-aws-virginia/test-trainingjob/valid/',\n",
    "          'test' :'s3://work-aws-virginia/test-trainingjob/test/',\n",
    "          'src':'s3://work-aws-virginia/test-trainingjob/src/'},\n",
    "          wait=False\n",
    ")"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit\n",
    "\n",
    "・並行してジョブ発行する場合は、wait=Falseを使う"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python374jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}